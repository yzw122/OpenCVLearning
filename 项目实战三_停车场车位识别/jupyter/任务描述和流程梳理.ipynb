{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8e3967",
   "metadata": {},
   "source": [
    "## 任务描述\n",
    "停车场车位识别任务，主要完成下面几件事情：\n",
    "1. 在整个停车场当中，一共有多少辆车，一共有多少个空余的停车位，这样就能知道有多少个停车位是空余的\n",
    "2. 把空余的停车位标识出来，这样用户停车的时候，就可以一步到位，直接去空余的停车位处，为停车节省了很多时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cdafbc",
   "metadata": {},
   "source": [
    "## 整体流程梳理\n",
    "1. 先通过一步过滤操作， 去掉多余的部分，只把停车场部分保留下来\n",
    "2. 把每一个停车位都给标记出来\n",
    "3. 训练模型判断当前的停车位有没有车(二分类任务)\n",
    "4. 把没有车的车位标识出来即可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d297b",
   "metadata": {},
   "source": [
    "## 数据介绍\n",
    "这里面用个test_images目录，这里面的两张图片就是从视频中截出来的两帧图像。 后面就是基于这两张图片进行预测操作。<br><br>这里面还有train目录，存放的是模型训练的的图片，这个就和之前做的那个花分类的任务一致了，这里为了增加难度，打算后面用pytorch去训练模型，而不是用keras了。正好拿这个项目练练手。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17e07c",
   "metadata": {},
   "source": [
    "## 图像预处理\n",
    "图像预处理主要是一些二值化，灰度化的一些操作，将图片中的重要信息进行突出显示。\n",
    "1. 首先是阈值的操作，把图片中的背景信息给过滤掉，具体的话是根据像素的阈值，制作了一个mask矩阵，然后把这个矩阵放到图片上进行遮盖，保留了有效的信息\n",
    "2. 接下来，把上面的图片转成了灰度图像\n",
    "3. 采用边缘检测算法，把图片中的边缘给找出来\n",
    "4. 特定点标定连线，把停车场的这部分图像保留下来，把停车场之外的图片给去掉，具体实施就是手动选取停车场周围的点，一般是角点，然后把线连起来\n",
    "5. 基于霍夫变换中的直线检测，去找到停车场中的直线， 后面要根据直线锁定车位\n",
    "6. 区域划分，把这个大的停车场划分成一列一列的，然后再从每一列里面去找停车位，然后标定号\n",
    "7. 选择出每一列去操作。通过手动坐标标定，把一个个的停车位找到拿出来"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e446cfc",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "这里是训练神经网络分类模型的过程，这里的网络是用的VGG16， 采用迁移学习的方式，一个原因是训练数据太少，从头开始训练效果不好，另一个是节省训练时间。训练完了之后，就对上面的一个个的停车位进行二分类的预测， 看看有没有车即可"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
