{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae5d9af",
   "metadata": {},
   "source": [
    "## Description:\n",
    "这个笔记本主要是处理原始图像，原始图像可能非常的不规整，且图片亮度上比较灰暗，所以要想进行准确的ocr识别，需要事先处理下原始图像。主要包括下面几个操作：\n",
    "1. 首先通过边缘检测，识别出需要识别的框体部分，即去掉冗余的背景啥的\n",
    "2. 通过轮廓检测，锁定框体外部的矩形框\n",
    "3. 透视变换操作，把矩形框及以内的内容进行规整\n",
    "\n",
    "下面就是每一步的具体操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e5b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079dae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_show(title, img):\n",
    "    cv2.imshow(title, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508ccdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    \"\"\"resize函数之所以自定义，是可以只指定高度或者高度\n",
    "        原理就是： \n",
    "        如果只指定某一个维度，图片的高度和宽度都会同比例缩小，比如指定height，那就宽度变成height/float(h)*w, 高度为height， 指定width同理\n",
    "        如果都指定， 那么就按照实际的大小resize\n",
    "    \"\"\"\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w*r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h*r))\n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5969b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图片\n",
    "image = cv2.imread(\"images/receipt.jpg\")  \n",
    "cv_show('img', image)     # 原始图片是2448*3264, 太大了，下面需要进行resize操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6a40f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2448, 3264, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c5aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize操作之前，需要保存resize的比例，以及原始图像\n",
    "# 下面要按照500的比例对图像进行resize， 那么原始图像的每个像素点的位置都会改变，记住ratio是为了最终能还原到原始的位置上去\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1222ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = resize(orig, height=500)\n",
    "cv_show('img', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbd8ea",
   "metadata": {},
   "source": [
    "## 边缘检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f7be1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理 转成灰度图 -> 高斯滤波 -> Canny边缘检测\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#gray = cv2.GaussianBlur(gray, (5, 5), 0)   边缘检测算法其实就是用的高斯滤波，所以这里这个不用发现更加清晰些\n",
    "edged = cv2.Canny(gray, 75, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05984c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('img', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4942eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('edge', edged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81418a9e",
   "metadata": {},
   "source": [
    "## 轮廓检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f494e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轮廓检测\n",
    "cnts, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a4b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面要获取到最外围的大轮廓， 因为我们只需要这个大轮廓里面的所有东西， 外面黑色的背景其实不需要\n",
    "for c in cnts:\n",
    "    # 计算轮廓近似\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    # C表示输入的点集\n",
    "    # epsilon表示从原始轮廓到近似轮廓的最大距离\n",
    "    # True表示封闭\n",
    "    approx = cv2.approxPolyDP(c, 0.02*peri, True)\n",
    "    \n",
    "    # 4个点的时候，说明是最外面的大轮廓，此时把这个拿出来\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce155cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "cv_show(\"Outline\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208144ef",
   "metadata": {},
   "source": [
    "## 透视变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed111eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # 一共4个坐标点\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    \n",
    "    # 下面这个操作，是因为这四个点目前是乱序的，下面通过了一种巧妙的方式来找到对应位置\n",
    "    # 左上和右下， 对于左上的这个点，(x,y)坐标和会最小， 对于右下这个点，(x,y)坐标和会最大，所以坐标求和，然后找最小和最大位置就是了\n",
    "    # 按照顺序找到对应坐标0123分别是左上， 右上， 右下，左下\n",
    "    s = pts.sum(axis=1)\n",
    "    # 拿到左上和右下\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    \n",
    "    # 右上和左下， 对于右上这个点，(x,y)坐标差会最小，因为x很大，y很小， 而左下这个点， x很小，y很大，所以坐标差会很大\n",
    "    # 拿到右上和左下\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda65a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    # 拿到正确的左上，右上， 右下，左下四个坐标点的位置\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    \n",
    "    # 计算输入的w和h值 这里就是宽度和高度，计算方式就是欧几里得距离，坐标对应位置相减平方和开根号\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    \n",
    "    # 变换后对应坐标位置   \n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # 计算变换矩阵  变换矩阵这里，要有原始的图像的四个点的坐标， 变换之后的四个点的对应坐标，然后求一个线性矩阵，相当于每个点通过一个线性映射\n",
    "    # 到新的图片里面去。那么怎么求线性矩阵呢？  \n",
    "    # 其实解线性方程组， 原始图片四个点坐标矩阵A(4, 2)， 新图片四个点坐标矩阵B(4, 2)， 在列这个维度上扩充1维1\n",
    "    # A变成了(4, 3), B也是(4, 3)， 每个点相当于(x, y, 1) \n",
    "    # B = WA， 其中W是3*3的矩阵，A的每个点是3*1， B的每个点是3*1\n",
    "    # W矩阵初始化[[h11, h12, h13], [h21, h22, h23], [h31, h32, 1]]  这里面8个未知数，通过上面给出的4个点\n",
    "    # 所以这里A， B四个点的坐标都扩充了1列，已知A,B四个点的坐标，这里去求参数，解8个线性方程组得到W，就是cv2.getPerspectiveTransform干的事情\n",
    "    # 这个文章说的不错：https://blog.csdn.net/overflow_1/article/details/80330835\n",
    "    W = cv2.getPerspectiveTransform(rect, dst)\n",
    "    # 有了透视矩阵W, 对于原始图片中的每个坐标， 都扩充1列，然后与W乘， 就得到了在变换之后图片的坐标点(x, y, z), 然后把第三列给去掉(x/z, y/z)就是最终的坐标\n",
    "    warped = cv2.warpPerspective(image, W, (maxWidth, maxHeight))\n",
    "\n",
    "    # 返回变换后结果\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50fb08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('img', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35f97663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面需要做透视变换， 让整个框里面的对象铺满整个图片，其余的地方去掉\n",
    "# 这个函数传入的是原始图片(resize之前的那个), resize之后的大轮廓坐标点乘以ratio，此时 轮廓坐标在resize之前图片里面的值\n",
    "# 这里是这样的， resize操作之后，其实原始图片的每个点的坐标都相对于原来点的坐标变小了，于是乎需要乘以这个ratio，才是在原始图片里面的坐标\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2)*ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f9f3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('warped', warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12a9dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二值处理\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "ref = cv2.threshold(warped, 150, 255, cv2.THRESH_BINARY)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d55c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('ref', ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0708165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = ref.shape[:2]\n",
    "center = (cols/2, rows/2)  # 以图像中心为旋转中心\n",
    "angle = 90                 # 顺时针旋转90°\n",
    "scale = 1                  # 等比例旋转，即旋转后尺度不变    \n",
    " \n",
    "M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "rotated_img = cv2.warpAffine(ref, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "902ffb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('scan_img', rotated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f34dd9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_img = resize(rotated_img, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa482503",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('resize_img', resize_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10e491aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存到文件\n",
    "cv2.imwrite('images/scan.jpg', rotated_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
